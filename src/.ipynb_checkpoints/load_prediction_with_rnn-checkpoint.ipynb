{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score, mean_absolute_error, mean_squared_log_error, median_absolute_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MASE(training_series, testing_series, prediction_series, m=365):\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(  np.diff( training_series) ).sum()/(n-1)\n",
    "#     i=0\n",
    "#     d = 0\n",
    "#     while (i+m) < n:\n",
    "#         d += np.abs(training_series[i]-training_series[i+m])\n",
    "#         i += 1\n",
    "#     d = d/(n-m)\n",
    "    errors = np.abs(testing_series - prediction_series )\n",
    "    return errors.mean()/d\n",
    "\n",
    "def MAPE(y_true, y_pred):\n",
    "    mape = 100*sum(np.divide(np.abs(y_true-y_pred),y_true))/len(y_true)\n",
    "    return mape[0]\n",
    "\n",
    "def next_batch(training_data,batch_size,steps,start_point):\n",
    "    # Grab a random starting point for each batch\n",
    "    # rand_start = np.random.randint(0,len(training_data)-steps*2) \n",
    "    rand_start = start_point\n",
    "    # Create Y data for time series in the batches\n",
    "    y_batch = np.array(training_data[rand_start:rand_start+steps+1]).reshape(1,steps+1)\n",
    "    X_batch = np.array(training_data[rand_start:rand_start+steps]).reshape(-1, steps, 1)\n",
    "    y_batch = np.array(training_data[rand_start+steps:rand_start+steps*2]).reshape(-1, steps, 1)\n",
    "    start_point += steps\n",
    "    if (start_point + 2*steps) >= len(training_data):\n",
    "        start_point = 0\n",
    "    return X_batch, y_batch, start_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/model_coast.ckpt\n",
      "error1\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_east.ckpt\n",
      "2000  train errors:\teast\tRMSE: 116.2232 \tMAE: 90.2296 \tMASE: 1.0379 \tMAPE: 6.4934\n",
      "3000  test  errors:\teast\tRMSE: 208.948 \tMAE: 153.4987 \tMASE: 1.7657 \tMAPE: 9.6753\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_ercot.ckpt\n",
      "2000  train errors:\tercot\tRMSE: 3344.7559 \tMAE: 2574.23 \tMASE: 1.4156 \tMAPE: 6.6832\n",
      "3000  test  errors:\tercot\tRMSE: 5075.2127 \tMAE: 3872.395 \tMASE: 2.1295 \tMAPE: 8.5415\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_far_west.ckpt\n",
      "2000  train errors:\tfar_west\tRMSE: 118.9537 \tMAE: 93.6057 \tMASE: 2.0045 \tMAPE: 5.6333\n",
      "3000  test  errors:\tfar_west\tRMSE: 341.2488 \tMAE: 313.5482 \tMASE: 6.7143 \tMAPE: 10.8414\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_north.ckpt\n",
      "2000  train errors:\tnorth\tRMSE: 39.7342 \tMAE: 30.5424 \tMASE: 0.7141 \tMAPE: 3.6436\n",
      "3000  test  errors:\tnorth\tRMSE: 107.3958 \tMAE: 78.105 \tMASE: 1.8261 \tMAPE: 8.41\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_north_c.ckpt\n",
      "2000  train errors:\tnorth_c\tRMSE: 1228.3324 \tMAE: 930.5465 \tMASE: 1.1577 \tMAPE: 7.2555\n",
      "3000  test  errors:\tnorth_c\tRMSE: 2126.5604 \tMAE: 1589.7081 \tMASE: 1.9777 \tMAPE: 10.6039\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_south_c.ckpt\n",
      "2000  train errors:\tsouth_c\tRMSE: 431.9306 \tMAE: 326.6842 \tMASE: 0.9304 \tMAPE: 5.2443\n",
      "3000  test  errors:\tsouth_c\tRMSE: 869.3613 \tMAE: 628.9315 \tMASE: 1.7912 \tMAPE: 9.0927\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_southern.ckpt\n",
      "2000  train errors:\tsouthern\tRMSE: 189.2115 \tMAE: 142.1592 \tMASE: 0.9201 \tMAPE: 4.5551\n",
      "3000  test  errors:\tsouthern\tRMSE: 515.5386 \tMAE: 348.9366 \tMASE: 2.2584 \tMAPE: 9.4765\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/model_west.ckpt\n",
      "2000  train errors:\twest\tRMSE: 62.0736 \tMAE: 45.5144 \tMASE: 0.8682 \tMAPE: 4.1193\n",
      "3000  test  errors:\twest\tRMSE: 193.3461 \tMAE: 147.0812 \tMASE: 2.8055 \tMAPE: 10.9376\n"
     ]
    }
   ],
   "source": [
    "datasetnames=[\"coast\",\"east\",\"ercot\",\"far_west\",\"north\",\"north_c\",\"south_c\",\"southern\",\"west\"]\n",
    "\n",
    "#datasetnames=[\"coast\"]\n",
    "\n",
    "for dtindx in range(len(datasetnames)):\n",
    "\n",
    "    datasetName = datasetnames[dtindx]\n",
    "    train = pd.read_csv('../data/Daily_Load_Data/train/'+datasetName+'.csv',index_col='Time')\n",
    "    test = pd.read_csv('../data/Daily_Load_Data/test/'+datasetName+'.csv',index_col='Time')\n",
    "    train = train.dropna(axis=0)\n",
    "    test = test.dropna(axis=0)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "\n",
    "    # Just one feature, the time series\n",
    "    num_inputs = 1\n",
    "    # Num of steps in each batch\n",
    "    num_time_steps = 365\n",
    "    # 100 neuron layer, play with this\n",
    "    num_neurons = 1500\n",
    "    # number of layer\n",
    "    num_layers = 3\n",
    "    # Just one output, predicted time series\n",
    "    num_outputs = 1\n",
    "    ## You can also try increasing iterations, but decreasing learning rate\n",
    "    # learning rate you can play with this\n",
    "    learning_rate = 0.001\n",
    "    # how many iterations to go through (training steps), you can play with this\n",
    "    num_train_iterations = 1000\n",
    "    # Size of the batch of data\n",
    "    batch_size = 1\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, num_time_steps, num_inputs])\n",
    "    y = tf.placeholder(tf.float32, [None, num_time_steps, num_outputs])\n",
    "\n",
    "    cell = tf.contrib.rnn.OutputProjectionWrapper(tf.nn.rnn_cell.MultiRNNCell(\n",
    "        [tf.nn.rnn_cell.GRUCell(num_units=num_neurons, activation=tf.nn.relu) \n",
    "                                        for layer in range(num_layers)]),\n",
    "                                        output_size=num_outputs)\n",
    "#     cell = tf.contrib.rnn.OutputProjectionWrapper(tf.nn.rnn_cell.MultiRNNCell(\n",
    "#         [tf.nn.rnn_cell.LSTMCell(num_units=num_neurons, activation=tf.nn.relu) \n",
    "#                                         for layer in range(num_layers)]),\n",
    "#                                         output_size=num_outputs)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "    loss = tf.reduce_mean(tf.square(outputs - y)) # MSE\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "    model_file_name = \"../../tmp/model_\"+datasetName+\".ckpt\"\n",
    "    saver = tf.train.Saver()\n",
    "    start_point = 0\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "#         sess.run(init)\n",
    "        saver.restore(sess, model_file_name)\n",
    "        for iteration in range(num_train_iterations+1):\n",
    "            X_batch, y_batch, start_point = next_batch(train_scaled,batch_size,num_time_steps,start_point)\n",
    "            sess.run(train, feed_dict={X: X_batch, y: y_batch})\n",
    "            if iteration % 1000 == 0 and iteration != 0:\n",
    "                try:\n",
    "                    #mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                    #print(iteration, \"\\tMSE:\", mse)\n",
    "                    \n",
    "                    # calculate train error\n",
    "                    s_point = 0\n",
    "                    mse = 0\n",
    "                    mae = 0\n",
    "                    mase = 0\n",
    "                    mape = 0\n",
    "                    trun = 10\n",
    "                    for i in range(trun):\n",
    "                        X_batch, y_batch, s_point = next_batch(train_scaled,batch_size,num_time_steps,s_point)\n",
    "                        y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "                        results = scaler.inverse_transform(y_pred.reshape(num_time_steps,1))\n",
    "                        true_data = y_batch.reshape(num_time_steps,1)\n",
    "                        true_data = scaler.inverse_transform(true_data)\n",
    "                        n = min(results.shape[0],true_data.shape[0])\n",
    "\n",
    "                        y_pred = results[:n]\n",
    "                        y_true = true_data[:n]\n",
    "\n",
    "                        mse += mean_squared_error(y_true=y_true,y_pred=y_pred)\n",
    "                        mae += mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "\n",
    "                        train_series = scaler.inverse_transform(train_scaled)\n",
    "                        mase += MASE(train_series.ravel(),y_true.ravel(),y_pred.ravel())\n",
    "                        mape += MAPE(y_true, y_pred)\n",
    "                    mse /= trun\n",
    "                    mae /= trun \n",
    "                    mase /= trun\n",
    "                    mape /= trun\n",
    "                    print(2000+iteration,\" train errors:\\t\"+datasetName+'\\tRMSE:', round(mse**0.5,4), '\\tMAE:', \n",
    "                          round(mae,4), '\\tMASE:', round(mase,4), '\\tMAPE:', round(mape,4))\n",
    "                    \n",
    "                    #test error\n",
    "                    train_seed = list(train_scaled[-num_time_steps:])\n",
    "                    X_batch = np.array(train_seed[-num_time_steps:]).reshape(1, num_time_steps, 1)\n",
    "                    y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "                    results = scaler.inverse_transform(y_pred.reshape(num_time_steps,1))\n",
    "                    true_data = test.values\n",
    "                    n = min(results.shape[0],true_data.shape[0])\n",
    "\n",
    "                    y_pred = results[:n]\n",
    "                    y_true = true_data[:n]\n",
    "\n",
    "                    mse = mean_squared_error(y_true=y_true,y_pred=y_pred)\n",
    "                    mae = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "\n",
    "                    train_series = scaler.inverse_transform(train_scaled)\n",
    "                    mase = MASE(train_series.ravel(),y_true.ravel(),y_pred.ravel())\n",
    "                    mape = MAPE(y_true, y_pred)\n",
    "\n",
    "                    print(2000+iteration,\" test  errors:\\t\"+datasetName+'\\tRMSE:', round(mse**0.5,4), '\\tMAE:', \n",
    "                          round(mae,4), '\\tMASE:', round(mase,4), '\\tMAPE:', round(mape,4))\n",
    "                    saver.save(sess, model_file_name)\n",
    "                except Exception as e:\n",
    "                    print(\"error1\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(abs(y_pred-y_true))/len(y_true)\n",
    "# plt.plot(y_true.ravel())\n",
    "# plt.plot(y_pred.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # d = np.abs(np.diff(y_true)).sum()\n",
    "# # print(d)\n",
    "# d =(np.diff(y_true.ravel()))\n",
    "# d= sum(abs(d))/len(d)\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#             # calculate train error\n",
    "#             start_point = 0\n",
    "#             mse = 0\n",
    "#             mae = 0\n",
    "#             mase = 0\n",
    "#             mape = 0\n",
    "#             trun = 10\n",
    "#             for i in range(trun):\n",
    "#                 X_batch, y_batch, start_point = next_batch(train_scaled,batch_size,num_time_steps,start_point)\n",
    "#                 y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "#                 results = scaler.inverse_transform(y_pred.reshape(num_time_steps,1))\n",
    "#                 true_data = y_batch.reshape(num_time_steps,1)\n",
    "#                 true_data = scaler.inverse_transform(true_data)\n",
    "#                 n = min(results.shape[0],true_data.shape[0])\n",
    "\n",
    "#                 y_pred = results[:n]\n",
    "#                 y_true = true_data[:n]\n",
    "\n",
    "#                 mse += mean_squared_error(y_true=y_true,y_pred=y_pred)\n",
    "#                 mae += mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "\n",
    "#                 train_series = scaler.inverse_transform(train_scaled)\n",
    "#                 mase += MASE(train_series.ravel(),y_true.ravel(),y_pred.ravel())\n",
    "#                 mape += MAPE(y_true, y_pred)\n",
    "#             mse /= trun\n",
    "#             mae /= trun \n",
    "#             mase /= trun\n",
    "#             mape /= trun\n",
    "#             print(\"train errors:\\t\"+datasetName+'\\tRMSE:', round(mse**0.5,4), '\\tMAE:', \n",
    "#                   round(mae,4), '\\tMASE:', round(mase,4), '\\tMAPE:', round(mape,4))\n",
    "\n",
    "#             # calculate test error\n",
    "#             train_seed = list(train_scaled[-num_time_steps:])\n",
    "#             X_batch = np.array(train_seed[-num_time_steps:]).reshape(1, num_time_steps, 1)\n",
    "#             y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "#             results = scaler.inverse_transform(y_pred.reshape(num_time_steps,1))\n",
    "#             true_data = test.values\n",
    "#             n = min(results.shape[0],true_data.shape[0])\n",
    "\n",
    "#             y_pred = results[:n]\n",
    "#             y_true = true_data[:n]\n",
    "\n",
    "#             mse = mean_squared_error(y_true=y_true,y_pred=y_pred)\n",
    "#             mae = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "\n",
    "#             train_series = scaler.inverse_transform(train_scaled)\n",
    "#             mase = MASE(train_series.ravel(),y_true.ravel(),y_pred.ravel())\n",
    "#             mape = MAPE(y_true, y_pred)\n",
    "\n",
    "#             print('test errors:\\t'+datasetName+'\\tRMSE:', round(mse**0.5,4), '\\tMAE:', \n",
    "#                   round(mae,4), '\\tMASE:', round(mase,4), '\\tMAPE:', round(mape,4))\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(\"error2\")\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "# prediction\n",
    "    #train_seed = list(train_scaled[-num_time_steps:])\n",
    "    \n",
    "    ## Now create a for loop that \n",
    "#     for iteration in range(num_time_steps):\n",
    "#         X_batch = np.array(train_seed[-num_time_steps:]).reshape(1, num_time_steps, 1)\n",
    "#         y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "#         train_seed.append(y_pred[0, -1, 0])\n",
    "#     results = scaler.inverse_transform(np.array(train_seed[num_time_steps:]).reshape(num_time_steps,1))\n",
    "    \n",
    "    #X_batch = np.array(train_seed[-num_time_steps:]).reshape(1, num_time_steps, 1)\n",
    "    #y_pred = sess.run(outputs, feed_dict={X: X_batch})\n",
    "    #results = scaler.inverse_transform(y_pred.reshape(num_time_steps,1))\n",
    "    #true_data = test.values\n",
    "    #n = min(results.shape[0],true_data.shape[0])\n",
    "    #y_pred = results[:n]\n",
    "    #y_true = true_data[:n]\n",
    "    \n",
    "    #mse = mean_squared_error(y_true=y_true,y_pred=y_pred)\n",
    "    #print('RMSE:', mse**0.5)\n",
    "#     evs = explained_variance_score(y_true=y_true,y_pred=y_pred)\n",
    "#     print('EVS:', evs)\n",
    "    #mae = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "    #print('MAE:', mae)\n",
    "#     msle = mean_squared_log_error(y_true=y_true,y_pred=y_pred)\n",
    "#     print('MSLE:', msle)\n",
    "#     meae = median_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "#     print('MEAE:', meae)\n",
    "#     r2 = r2_score(y_true=y_true,y_pred=y_pred)\n",
    "#     print('R2-Score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truedf = pd.DataFrame(data=y_true)\n",
    "y_preddf = pd.DataFrame(data=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truedf.to_csv(\"y_true.csv\")\n",
    "y_preddf.to_csv(\"y_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.425090952262878"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASE(train_series.ravel(),y_true.ravel(),y_pred.ravel(),m=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
